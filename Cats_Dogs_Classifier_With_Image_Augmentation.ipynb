{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Importing the Library and Installing WGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wget is a free software package for retrieving files on the Internet using the most widely used network protocols. Wget is not a pre-installed library, and the following code installs the Python Package through the command/anaconda prompt. This library will be used to download the dataset of 25,000 images from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Using WGET to Download the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is expected to feed the path for the base folder in the provided space. This portion of the code is used for creation of a folder to store the dataset followed by downloading the complete dataset from the website. This is the dataset that we will be training the model on. The Train/Test split can be decided in the upcoming sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "def bar_custom(current, total, width=80):\n",
    "    print(\"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total))\n",
    "\n",
    "base_folder_path = r'Insert Base Folder Path Here' #Insert Base Folder Path Here\n",
    "os.mkdir('Dataset')\n",
    "dataset = os.path.join(base_folder_path, 'Dataset')\n",
    "\n",
    "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
    "wget.download(url, bar = bar_custom, out = \"{}\\Cats_Vs_Dogs.zip\".format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Extracting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset downloaded from the website is in the form of a .zip file. So, this section of the notebook is dedicated to extracting the zip file to the parent folder. To manage the storage better, the zip file gets deleted after extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip = \"{}\\Cats_Vs_Dogs.zip\".format(dataset)\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('{}'.format(dataset))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"{}\\Cats_Vs_Dogs.zip\".format(dataset)):\n",
    "    os.remove(\"{}\\Cats_Vs_Dogs.zip\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('{}/PetImages/Cat/'.format(dataset))))\n",
    "print(len(os.listdir('{}/PetImages/Dog/'.format(dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Image Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Data Generator is a function within Tensorflow Preprocessing Library. It can be used to generate batches of tensor image data with real-time data augmentation. Image Data Generators requires that the dataset is labelled and sorted into right folders. Two primary folders within the Dataset folder is required for optimum functioning of the library, namely Training and Testing/Validation. Image Data Generator is particularly useful in cases of multi-class classification problems. It is required that the files are sorted in a certain way before the model is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Creating Sub-Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Sub-Directories for the Dataset to be used within the IDG function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_create = [\n",
    "    '{}/Cats_Vs_Dogs'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/training'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/testing'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/training/Cats'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/training/Dogs'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/testing/Cats'.format(dataset),\n",
    "    '{}/Cats_Vs_Dogs/testing/Dogs'.format(dataset)\n",
    "]\n",
    "\n",
    "for directory in folders_to_create:\n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "        print(directory, 'Created')\n",
    "    except:\n",
    "        print(directory, 'Failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Sorting the Files to Respective Sub-Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    all_files = []\n",
    "    \n",
    "    for file_name in os.listdir(SOURCE):\n",
    "        file_path = SOURCE + file_name\n",
    "\n",
    "        if os.path.getsize(file_path):\n",
    "            all_files.append(file_name)\n",
    "        else:\n",
    "            print('{} is being Discarded due to Zero File Size'.format(file_name))\n",
    "    \n",
    "    n_files = len(all_files)\n",
    "    split_point = int(n_files * SPLIT_SIZE)\n",
    "    \n",
    "    shuffled = random.sample(all_files, n_files)\n",
    "    \n",
    "    train_set = shuffled[:split_point]\n",
    "    test_set = shuffled[split_point:]\n",
    "    \n",
    "    for file_name in train_set:\n",
    "        copyfile(SOURCE + file_name, TRAINING + file_name)\n",
    "        \n",
    "    for file_name in test_set:\n",
    "        copyfile(SOURCE + file_name, TESTING + file_name)\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = '{}/PetImages/Cat/'.format(dataset)\n",
    "TRAINING_CATS_DIR = '{}/Cats_Vs_Dogs/training/Cats/'.format(dataset)\n",
    "TESTING_CATS_DIR = '{}/Cats_Vs_Dogs/training/Cats/'.format(dataset)\n",
    "DOG_SOURCE_DIR = '{}/PetImages/Dog/'.format(dataset)\n",
    "TRAINING_DOGS_DIR = '{}/Cats_Vs_Dogs/training/Dogs/'.format(dataset)\n",
    "TESTING_DOGS_DIR = '{}/Cats_Vs_Dogs/testing/Dogs/'.format(dataset)\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'C:\\Users\\offic\\Convolutional Neural Networks in Tensorflow\\Cats vs Dogs'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "print(train_cat_fnames[:10])\n",
    "print(train_dog_fnames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Training Cat Images :', len(os.listdir(train_cats_dir)))\n",
    "print('Total Training Dog Images :', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('Total Validation Cat Images :', len(os.listdir(validation_cats_dir)))\n",
    "print('Total Validation Dog Images :', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Defining the layers of Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Setting the ImageDataGenerator Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator(rescale=1 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    shear_range=.2,\n",
    "    zoom_range=.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest.)\n",
    "test_datagen  = ImageDataGenerator(rescale=1 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    shear_range=.2,\n",
    "    zoom_range=.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest)\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(256, 256))     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode = 'binary',\n",
    "                                                         target_size = (256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "                    epochs = 150,\n",
    "                    validation_steps = 50,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, label = 'Training Accuracy', color = 'Red')\n",
    "plt.plot(epochs, val_acc, label = 'Validation Accuracy', color = 'Blue')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, label = 'Training Loss', color = 'Red')\n",
    "plt.plot(epochs, val_loss, label = 'Validation Loss', color = 'Blue')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
